{"cells":[{"cell_type":"markdown","metadata":{"id":"986S2Td-HJpZ"},"source":["# Extractive Summary as Text Matching on *FairySum*  ðŸ§š"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## prove"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","\n","data_path=\"/home/lavallone/Desktop/NUANS/NUANS/Project/match_sum_experiments_data/ACL2020_data/test_CNNDM_bert.jsonl\"\n","data = []\n","with open(data_path) as f:\n","    for line in f:\n","        data.append(json.loads(line))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(len(data)):\n","    print(data[i][\"label\"])\n","    print(len(data[i][\"indices\"]))\n","    print(len(data[i][\"score\"]))\n","    print(len(data[i][\"candidate_id\"]))\n","    \n","    print(len(data[i][\"candidate_id\"][0]))\n","    print(len(data[i][\"candidate_id\"][1]))\n","    \n","len(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","gold = {}\n","for file_name in [\"FairySum/gold/\"+x for x in os.listdir(\"FairySum/gold/\")]:\n","  key = file_name.split(\"/\")[-1]\n","  key = \"_\".join(key.split(\"_\")[:2])\n","  f = open(file_name, 'r')\n","  lines = f.readlines()\n","  text = []\n","  for l in lines:\n","    i = l.index(\":\") + 2\n","    text.append(l[i:-1])\n","  if key in gold.keys():\n","    gold[key] += len(text)\n","  else:\n","    gold[key] = len(text)\n","\n","c=Counter()\n","c.update([f[:-12] for f in os.listdir(\"FairySum/gold\")])\n","for k,_ in gold.items():\n","  gold[k]= round(gold[k]/c[k])\n","\n","#json.dump(gold, open(\"data/gold_length.json\", \"w\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a quanto pare manca un testo in gold \n","texts = json.load(open(\"data/texts.json\",\"r\"))\n","for k in texts.keys():\n","    if k not in gold.keys():\n","        print(k)\n","        \n","# manca 'bn_02975525n_Rothschild_s Violin'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget https://www.gutenberg.org/files/208/208.txt -O 208_daisy_miller.txt\n","from booknlp.booknlp import BookNLP\n","model_params={\n","\t\t\"pipeline\":\"entity,quote,supersense,event,coref\", \n","\t\t\"model\":\"big\", \n","\t}\n","\n","booknlp=BookNLP(\"en\", model_params)\n","inputFile=\"208_daisy_miller.txt\"\n","outputDir=\"208_daisy_miller/\"\n","idd=\"208_daisy_miller\"\n","\n","booknlp.process(inputFile, outputDir, idd)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Imports & Downloads"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# install the requirements\n","%pip install -r requirements.txt > /dev/null\n","# set to false if you already have the dataset\n","download_dataset = False \n","if download_dataset:\n","    %cd FairySum\n","    !bash download_dataset.sh\n","    %cd .."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#from src.data_module import MVTec_Dataset, MVTec_DataModule\n","#from src.AE_simple import AE\n","#from src.AE_CODE import CODE_AE\n","#from src.AE_mixer import Mixer_AE\n","#from src.hyperparameters import Hparams\n","#from src.train import train_model\n","from src.hyperparameters import Hparams\n","from sbert.baseline import SentenceBERT\n","from sbert.regression_model import execute_booknlp_pipeline\n","from sbert.regression_model import count_event_sentence\n","from sbert.regression_model import LengthRegressionModel\n","\n","import dataclasses\n","from dataclasses import asdict\n","import matplotlib.pyplot as plt\n","import wandb\n","import pprint\n","import json\n","import torchvision\n","import pytorch_lightning as pl\n","import gc\n","from collections import Counter\n","import seaborn as sns\n","from tqdm import tqdm\n","from booknlp.booknlp import BookNLP\n","import os\n","import pandas as pd\n","import numpy as np\n","from math import comb\n","import random\n","# reproducibility stuff\n","import numpy as np\n","import random\n","import torch\n","np.random.seed(0)\n","random.seed(0)\n","torch.cuda.manual_seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n","torch.backends.cudnn.benchmark = False\n","_ = pl.seed_everything(0)\n","# to have a better workflow using notebook https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n","# these commands allow to update the .py codes imported instead of re-importing everything every time.\n","%load_ext autoreload\n","%autoreload 2\n","#%env WANDB_NOTEBOOK_NAME = ./notebook.ipynb\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# order a dictionary based on its keys in order to manipulate it better\n","def order_dict(d):\n","    keys = list(d.keys())\n","    keys.sort()\n","    ris = {i: d[i] for i in keys}\n","    return ris\n","\n","# selection strategy - candidates creation\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Preprocessing"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Candidates Extraction"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Phase 1** - *output summaries length regression*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# training the regression model for predicting the best summary length (i.e. the number of sentences to be extracted)\n","\n","\"\"\"\n","    - The original texts length are saved in 'original_length.json' file. \n","    - The golden output lengths (that are the computed average lenghts of the manually annotated summaries by the students) are saved \n","      in the 'gold_length.json' file.\n","      We now need to compute a quantity which quantifies somehow the concentration of events in each story. We leverage the BookNLP library \n","      to do so. The adopted strategy is very simple: once the library has detected the events, we count the number of unique sentences that\n","      contain at least one EVENT (it means that these sentences are relevant for the story).\n","\"\"\"\n","\n","texts = json.load(open(\"data/texts.json\",\"r\"))\n","\n","booknlp_already_computed = True if os.path.isdir(\"data/booknlp_processed_texts\")==True else False\n","if not booknlp_already_computed:\n","  !python -m spacy download en_core_web_sm > /dev/null # needed for the BookNLP library\n","  model_params={\"pipeline\":\"entity,event\", \"model\":\"big\"}\n","  booknlp = BookNLP(\"en\", model_params)\n","  texts = json.load(open(\"data/texts.json\",\"r\"))\n","  execute_booknlp_pipeline(booknlp, texts)\n","  !rm \"data/current_story.txt\"\n","  !rm -r \"data/current\"\n","  \n","events_already_computed = True\n","if not events_already_computed:\n","  count_event_sentence(\"data/booknlp_processed_texts/\", texts)\n","\n","# starting the regression phase\n","# since we miss one golden summary --> 'bn_02975525n_Rothschild_s Violin', we need to remove it from 'events' and from 'original_lenghts'\n","events = json.load(open(\"data/events.json\",\"r\"))\n","del events[\"bn_02975525n\"]\n","events = order_dict(events)\n","\n","gold_lengths = json.load(open(\"data/gold_length.json\",\"r\"))\n","gold_lengths = order_dict(gold_lengths)\n","original_lenghts = json.load(open(\"data/original_length.json\",\"r\"))\n","del original_lenghts[\"bn_02975525n\"]\n","original_lenghts = order_dict(original_lenghts)\n","\n","# instantiate the regression model for predicting  the output length of our generated extractive summaries\n","LengthRegressionModel = LengthRegressionModel(gold_lengths, original_lenghts, events)\n","# LengthRegressionModel.plot() # if we want to plot the regression curve\n","LengthRegressionModel.fit()\n","predictions = LengthRegressionModel.predict()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Phase 2** - *sentences extraction*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hparams = asdict(Hparams())\n","hparams[\"sbert_mode\"] = \"extraction\"\n","sbert = SentenceBERT(hparams, predictions)\n","\n","texts = json.load(open(\"data/texts.json\",\"r\"))\n","extracted_sentences = sbert(texts) # we receive a dictionary with the extracted sentences indices for each story"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Phase 3** - *sentences selection*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# selection strategy\n","\n","k_range = hparams[\"k_range\"]\n","pick_random_n = hparams[\"pick_random_n\"]\n","\n","candidates_dict = {}\n","for k,v in extracted_sentences.items():\n","    candidates_list = []\n","    candidates_list.append(v)\n","    n = len(v)\n","    for i in range(n-k_range, n):\n","        #c = comb(n, i) # total number of combinations\n","        random_idx = []\n","        for _ in range(pick_random_n): # how many random combinations?\n","            candidates_list.append([v[i] for i in sorted(random.sample(range(n), i))])\n","            \n","    candidates_dict[k] = candidates_list\n","    \n","# save them\n","json.dump(candidates_dict, open(\"data/candidates/candidates.json\", \"w\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Abstractive Summaries"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We use  the SOTA **PEGASUS model** for computing the abstractive summaries needed  for  training. We simply download a pretrained model and use it as it is (*plug-and-play*)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n","\n","# create the tokenizer\n","tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n","\n","# load the model\n","torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\").to(torch_device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# we need to know wich are the training texts\n","train_keys = []\n","for f in os.listdir(\"FairySum/texts/train/\"):\n","    k = \"_\".join(f.split(\"_\")[:2])\n","    train_keys.append(k)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["texts = json.load(open(\"data/texts.json\",\"r\"))\n","abstractives = {}\n","\n","# we make inference on this model\n","model.eval()\n","with torch.no_grad():\n","    for i, (k,v) in tqdm(enumerate(texts.items())):\n","        if k not in train_keys:\n","            continue\n","        # we need to have the text available as a whole\n","        text = \" \".join([e+\"\\n\" for e in v])\n","        # create tokens batch\n","        batch = tokenizer.prepare_seq2seq_batch(text, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(torch_device)\n","        # summary in tokens\n","        summary = model.generate(**batch)\n","        # (we need to decode it)\n","        abstractive_output = tokenizer.batch_decode(summary, skip_special_tokens=True)[0]\n","        abstractives[k] = abstractive_output\n","        ##########################\n","        ####   free GPU RAM   ####\n","        ##########################\n","        del batch\n","        del summary\n","        del abstractive_output\n","        torch.cuda.empty_cache()\n","        ##########################\n","        \n","# save the dictionary\n","json.dump(abstractives, open(\"data/abstractives/abstractives.json\", \"w\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> We use *pegasus-large* pretrainied model because it outputs longer summaries, but since it is trained mainly on news articles which are shorter than our dataset, the output summaries are certainly not ideal. This can be a research direction to follow for future improvements of the overall method. For this mini-project we keep the model as it is, hoping in the achievement of decent results."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Gold Summaries processing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# we want to create a dictionary for each gold summary with only the sentences indeces\n","# of course only of the TRAIN texts\n","gold = {}\n","for file_name in [\"FairySum/gold/\"+x for x in os.listdir(\"FairySum/gold/\")]:\n","  key = file_name.split(\"/\")[-1]\n","  key = \"_\".join(key.split(\"_\")[:2])\n","  if key not in train_keys:\n","    continue\n","  f = open(file_name, 'r')\n","  lines = f.readlines()\n","  text = []\n","  for l in lines:\n","    i = l.index(\":\")\n","    text.append(int(l[:i]))\n","  if key in gold.keys(): # if we have more than one gold summary we apppend to the list\n","    gold[key].append(text)\n","  else:\n","    gold[key] = [text]\n","    \n","# save the dictionary\n","json.dump(gold, open(\"data/gold/gold.json\", \"w\"))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Tokenization ?"]},{"cell_type":"markdown","metadata":{"id":"-y0tDVGRwJLp"},"source":["## MatchSum"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Finetuning on FairySum"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4-BXw5Fav7VF"},"source":["### ROUGE installation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-N2nAFFEVpP1"},"outputs":[],"source":["## ROUGE installation --> it's been a nightmare! ##\n","!sudo apt-get install libxml-dom-perl\n","%cd /content\n","!git clone https://github.com/andersjo/pyrouge\n","!cp -r pyrouge/tools/ROUGE-1.5.5 /content/ROUGE\n","!rm -r pyrouge\n","!export ROUGE_EVAL_HOME=\"/content/ROUGE/data/\"\n","%cd /content/ROUGE/data/WordNet-2.0-Exceptions/\n","!rm  WordNet-2.0.exc.db\n","!./buildExeptionDB.pl . exc WordNet-2.0.exc.db\n","%cd ..\n","!rm  WordNet-2.0.exc.db\n","!ln -s WordNet-2.0-Exceptions/WordNet-2.0.exc.db WordNet-2.0.exc.db\n","\n","%cd /content\n","!git clone https://github.com/bheinzerling/pyrouge\n","%cd /content/pyrouge\n","!python setup.py install\n","!pyrouge_set_rouge_path /content/ROUGE/\n","#!python -m pyrouge.test\n","\n","!pip install pyrouge==0.1.3\n","!pip install rouge==1.0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KdKjtJryK2Kh"},"outputs":[],"source":["## CLONING REPO ##\n","%cd /content\n","!rm -rf NUANS > /dev/null\n","!git clone https://github.com/lavallone/NUANS.git\n","%cd /content/NUANS/Homework_02/MatchSum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9jRiuKqWuno"},"outputs":[],"source":["!git pull\n","!CUDA_VISIBLE_DEVICES=0 python train_matching.py --mode=test --encoder=roberta --save_path=/content/models --gpus=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lnuwUyTX_bv"},"outputs":[],"source":["with open(\"/content/data/test_CNNDM_roberta.jsonl\") as json_file:\n","    l = list(json_file)\n","\n","l1=[]\n","for elem in l:\n","    elem = json.loads(elem)\n","    l1.append(elem)\n","\n","l1[0].keys() # ict_keys(['label', 'text', 'summary', 'ext_idx', 'indices', 'score', 'candidate_id', 'text_id', 'summary_id'])\n","len(l1[0][\"text\"])\n","len(l1[0][\"ext_idx\"]) # sono gli indici delle frasi piÃ¹ salienti \n","len(l1[0][\"indices\"]) # sono l'insieme delle frasi selezionate\n","len(l1[0][\"score\"]) # Ã¨ lo score delle 20 frasi selezionate\n","\n","# 'candidate_id', 'text_id', 'summary_id' sono le versioni tokenizzate dei candidati, del testo e del golden summary\n","# label Ã¨ una sorta di 'id' del sample del dataset"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sYnPaW3xqB76","o_pOiPmDqB78","UM9r2JPLqB79","dWYN7dXdqB7_","-6AfNu4BqB8A","8qebcYffqB8A","jGyjEQYeqB8B","3rN7DegMJpJB","P8ThCPp6Jt5c","7_K0zpGyqB8H","iCFsRmN9qB8I"],"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.4 ('sappia')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"5f06e66338bb5301debc8a4cff3b178f3ee2a0c1aca00670585ce1ed8b6c95da"}}},"nbformat":4,"nbformat_minor":0}
